{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "\n",
    "PACKAGE_PARENT = '../../../../'\n",
    "sys.path.append(PACKAGE_PARENT)\n",
    "\n",
    "from alphaslime.agents.RL.policygrad.torch.ppo import PPOAgent\n",
    "import ppo_training_configs as PPOCONFIGS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load configurations\n",
    "CONST = PPOCONFIGS.CONST\n",
    "agent_config = PPOCONFIGS.agent_config\n",
    "env = PPOCONFIGS.env"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from alphaslime.evaluate.eval_agents import EvaluateGameSA\n",
    "\n",
    "# create agent\n",
    "agent_trained = PPOAgent(CONSTANTS=CONST, config=agent_config)\n",
    "\n",
    "# load trained models\n",
    "actor_path = ''\n",
    "critic_path = ''\n",
    "paths = [actor_path, critic_path]\n",
    "agent_trained.load_model(paths)\n",
    "\n",
    "\n",
    "eps = 2\n",
    "base_dir_path = \"./\"\n",
    "RENDER = True\n",
    "gym_evaluator = EvaluateGameSA(agent_trained, env, base_dir_path, render=RENDER)\n",
    "running_avg_len = 100\n",
    "running_avg_len = 2\n",
    "\n",
    "\n",
    "# evaulate agent\n",
    "rewards, avg_rewards_array = gym_evaluator.evaluate(eps, is_progress_bar=True, running_avg_len=running_avg_len)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"average reward per episode :\", sum(rewards) / len(rewards))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rewards = np.array(rewards)\n",
    "plt.plot(rewards, label='Reward')\n",
    "plt.plot(avg_rewards_array, label='Average reward')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1)) \n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('reward Value')\n",
    "print('average reward per episode= {}'.format(np.mean(rewards)))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "f41a9e18d32d699c7ebd9346171aa8606b8eaf6d2e7d29caa03f22c5e982b824"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}