{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained slime agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PACKAGE_PARENT = '../'\n",
    "sys.path.append(PACKAGE_PARENT)\n",
    "from alphaslime.evaluate.eval_agents import EvaluateGameMA\n",
    "from alphaslime.agents.RL.policygrad.torch.ppo import PPOAgent\n",
    "from alphaslime.agents.imitate.torch.bcAgent import BCAgent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import slimevolleygym\n",
    "import pickle\n",
    "\n",
    "# constant config\n",
    "env_id = \"SlimeVolley-v0\"\n",
    "env = gym.make(env_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store are trained agents in a list\n",
    "agents = []\n",
    "\n",
    "# load PPO agent trained with baseline\n",
    "print('loading: ppo_agent')\n",
    "import trained_agents.ppo.slime.ppo_training_configs_cont as PPOCONFIGS\n",
    "CONST = PPOCONFIGS.CONST\n",
    "agent_config = PPOCONFIGS.agent_config\n",
    "act_path = '../trained_agents/ppo/slime/gamma_0.99_alpha_0.0003_reward_-0.22_model_actor.pt'\n",
    "crt_path = '../trained_agents/ppo/slime/gamma_0.99_alpha_0.0003_reward_-0.22_model_critic.pt'\n",
    "paths = [act_path, crt_path]\n",
    "ppo_agent = PPOAgent(CONSTANTS=CONST, config=agent_config)\n",
    "ppo_agent.load_model(paths)\n",
    "print('-'*10)\n",
    "\n",
    "# load Self-play PPO agent trained\n",
    "print('loading: sp_ppo_agent')\n",
    "import trained_agents.selfplay.slime.no_boots.pposp_configs_cont as SP_PPOCONFIGS\n",
    "CONST = SP_PPOCONFIGS.CONST\n",
    "agent_config = SP_PPOCONFIGS.agent_config\n",
    "act_path = '../trained_agents/selfplay/slime/no_boots/gamma_0.99_alpha_0.0003_reward_4.58_model_actor.pt'\n",
    "crt_path = '../trained_agents/selfplay/slime/no_boots/gamma_0.99_alpha_0.0003_reward_4.58_model_critic.pt'\n",
    "paths = [act_path, crt_path]\n",
    "sp_ppo_agent = PPOAgent(CONSTANTS=CONST, config=agent_config)\n",
    "sp_ppo_agent.load_model(paths)\n",
    "print('-'*10)\n",
    "\n",
    "# load bootstrapped PPO agent trained\n",
    "print('loading: boots_ppo_agent')\n",
    "import trained_agents.selfplay.slime.boots.pposp_configs_boots as BOOTS_PPOCONFIGS\n",
    "CONST = BOOTS_PPOCONFIGS.CONST\n",
    "agent_config = BOOTS_PPOCONFIGS.agent_config\n",
    "act_path = '../trained_agents/selfplay/slime/boots/gamma_0.99_alpha_0.0003_reward_4.61_model_actor.pt'\n",
    "crt_path = '../trained_agents/selfplay/slime/boots/gamma_0.99_alpha_0.0003_reward_4.61_model_critic.pt'\n",
    "paths = [act_path, crt_path]\n",
    "boots_ppo_agent = PPOAgent(CONSTANTS=CONST, config=agent_config)\n",
    "boots_ppo_agent.load_model(paths)\n",
    "print('-'*10)\n",
    "\n",
    "# load BC agent trained\n",
    "print('loading: bc_agent')\n",
    "import trained_agents.imitate.slime.bc_training_configs_extend as BCCONFIGS\n",
    "CONST = BCCONFIGS.CONST\n",
    "agent_config = BCCONFIGS.agent_config\n",
    "path = '../trained_agents/imitate/slime/alpha_0.0003_loss_7061._model_bc.pt'\n",
    "bc_agent = BCAgent(CONSTANTS=CONST, config=agent_config)\n",
    "bc_agent.load_model(path)\n",
    "print('-'*10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store agents in list\n",
    "agents.append(['PPO_Agent', ppo_agent])\n",
    "agents.append(['Self-play_PPO_Agent', sp_ppo_agent])\n",
    "agents.append(['Bootstrapped_Self-play_PPO_Agent', boots_ppo_agent])\n",
    "agents.append(['BC_Agent', bc_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent VS Agent\n",
    "\n",
    "eps = 1\n",
    "base_dir_path = \"./evaluate_data/\"\n",
    "RENDER = True\n",
    "running_avg_len = 100\n",
    "match_data = {}\n",
    "for agent_right_name, agent_right in agents:\n",
    "    for agent_left_name, agent_left in agents:\n",
    "\n",
    "        gym_evaluator = EvaluateGameMA(agent_right, agent_left, env, base_dir_path, render=RENDER, time_delay=0)\n",
    "\n",
    "        # evaulate agent\n",
    "        rewards, avg_rewards_array = gym_evaluator.evaluate(eps, is_progress_bar=True, running_avg_len=running_avg_len)\n",
    "\n",
    "        data_name = agent_right_name + '_vs_' + agent_left_name\n",
    "        match_data[data_name] = [rewards, avg_rewards_array]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "match_data_filename = 'match_data.pkl'\n",
    "# eval_path =  base_dir_path + match_data_filename\n",
    "\n",
    "# save file\n",
    "\n",
    "if not os.path.exists(base_dir_path):\n",
    "    os.makedirs(base_dir_path)\n",
    "\n",
    "\n",
    "eval_path = os.path.join(base_dir_path, match_data_filename)\n",
    "with open(eval_path, 'wb') as f:\n",
    "    pickle.dump(match_data, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35985fa570b046aa04235cd8243fe0dea46807f74224419e7c68de2515ef2690"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
